//
// Generated by NVIDIA NVVM Compiler
// Compiler built on Wed Sep 24 22:55:20 2014 (1411595720)
// Driver 340.46
//

.version 3.0
.target sm_30, texmode_independent
.address_size 32


.entry erode_kernel(
	.param .u32 .ptr .global .align 4 erode_kernel_param_0,
	.param .u32 .ptr .global .align 4 erode_kernel_param_1,
	.param .u32 erode_kernel_param_2,
	.param .u32 erode_kernel_param_3
)
{
	.reg .pred 	%p<4>;
	.reg .s32 	%r<44>;


	ld.param.u32 	%r19, [erode_kernel_param_0];
	ld.param.u32 	%r20, [erode_kernel_param_1];
	ld.param.u32 	%r21, [erode_kernel_param_2];
	// inline asm
	mov.u32 	%r1, %envreg3;
	// inline asm
	// inline asm
	mov.u32 	%r2, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r3, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r4, %tid.x;
	// inline asm
	add.s32 	%r22, %r4, %r1;
	mad.lo.s32 	%r23, %r3, %r2, %r22;
	// inline asm
	mov.u32 	%r5, %envreg6;
	// inline asm
	// inline asm
	mov.u32 	%r6, %ntid.x;
	// inline asm
	mul.lo.s32 	%r24, %r6, %r5;
	rem.s32 	%r25, %r23, %r21;
	sub.s32 	%r26, %r23, %r21;
	shl.b32 	%r27, %r26, 2;
	add.s32 	%r28, %r19, %r27;
	shr.s32 	%r29, %r26, 31;
	ld.global.u32 	%r30, [%r28];
	or.b32  	%r8, %r30, %r29;
	add.s32 	%r31, %r23, %r21;
	shl.b32 	%r32, %r31, 2;
	add.s32 	%r33, %r19, %r32;
	setp.ge.s32 	%p1, %r31, %r24;
	selp.b32 	%r34, -1, 0, %p1;
	ld.global.u32 	%r35, [%r33];
	or.b32  	%r9, %r35, %r34;
	shl.b32 	%r36, %r23, 2;
	add.s32 	%r37, %r36, %r19;
	setp.eq.s32 	%p2, %r25, 0;
	selp.b32 	%r38, -1, 0, %p2;
	ld.global.u32 	%r39, [%r37+-4];
	or.b32  	%r11, %r39, %r38;
	add.s32 	%r40, %r21, -1;
	setp.eq.s32 	%p3, %r25, %r40;
	selp.b32 	%r41, -1, 0, %p3;
	ld.global.u32 	%r42, [%r37+4];
	or.b32  	%r12, %r42, %r41;
	// inline asm
	min.u32 	%r7, %r8, %r9;
	// inline asm
	// inline asm
	min.u32 	%r10, %r11, %r12;
	// inline asm
	// inline asm
	min.u32 	%r13, %r7, %r10;
	// inline asm
	ld.global.u32 	%r18, [%r37];
	// inline asm
	min.u32 	%r16, %r13, %r18;
	// inline asm
	add.s32 	%r43, %r20, %r36;
	st.global.u32 	[%r43], %r16;
	ret;
}

.entry dilate_kernel(
	.param .u32 .ptr .global .align 4 dilate_kernel_param_0,
	.param .u32 .ptr .global .align 4 dilate_kernel_param_1,
	.param .u32 dilate_kernel_param_2,
	.param .u32 dilate_kernel_param_3
)
{
	.reg .pred 	%p<4>;
	.reg .s32 	%r<46>;


	ld.param.u32 	%r19, [dilate_kernel_param_0];
	ld.param.u32 	%r20, [dilate_kernel_param_1];
	ld.param.u32 	%r21, [dilate_kernel_param_2];
	// inline asm
	mov.u32 	%r1, %envreg3;
	// inline asm
	// inline asm
	mov.u32 	%r2, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r3, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r4, %tid.x;
	// inline asm
	add.s32 	%r22, %r4, %r1;
	mad.lo.s32 	%r23, %r3, %r2, %r22;
	// inline asm
	mov.u32 	%r5, %envreg6;
	// inline asm
	// inline asm
	mov.u32 	%r6, %ntid.x;
	// inline asm
	mul.lo.s32 	%r24, %r6, %r5;
	rem.s32 	%r25, %r23, %r21;
	sub.s32 	%r26, %r23, %r21;
	shl.b32 	%r27, %r26, 2;
	add.s32 	%r28, %r19, %r27;
	shr.u32 	%r29, %r26, 31;
	xor.b32  	%r30, %r29, 1;
	neg.s32 	%r31, %r30;
	ld.global.u32 	%r32, [%r28];
	and.b32  	%r8, %r32, %r31;
	add.s32 	%r33, %r23, %r21;
	shl.b32 	%r34, %r33, 2;
	add.s32 	%r35, %r19, %r34;
	setp.lt.s32 	%p1, %r33, %r24;
	selp.b32 	%r36, -1, 0, %p1;
	ld.global.u32 	%r37, [%r35];
	and.b32  	%r9, %r37, %r36;
	shl.b32 	%r38, %r23, 2;
	add.s32 	%r39, %r38, %r19;
	setp.ne.s32 	%p2, %r25, 0;
	selp.b32 	%r40, -1, 0, %p2;
	ld.global.u32 	%r41, [%r39+-4];
	and.b32  	%r11, %r41, %r40;
	add.s32 	%r42, %r21, -1;
	setp.ne.s32 	%p3, %r25, %r42;
	selp.b32 	%r43, -1, 0, %p3;
	ld.global.u32 	%r44, [%r39+4];
	and.b32  	%r12, %r44, %r43;
	// inline asm
	max.u32 	%r7, %r8, %r9;
	// inline asm
	// inline asm
	max.u32 	%r10, %r11, %r12;
	// inline asm
	// inline asm
	max.u32 	%r13, %r7, %r10;
	// inline asm
	ld.global.u32 	%r18, [%r39];
	// inline asm
	max.u32 	%r16, %r13, %r18;
	// inline asm
	add.s32 	%r45, %r20, %r38;
	st.global.u32 	[%r45], %r16;
	ret;
}

.entry update_kernel(
	.param .u32 .ptr .global .align 1 update_kernel_param_0,
	.param .u32 .ptr .global .align 1 update_kernel_param_1
)
{
	.reg .pred 	%p<12>;
	.reg .s32 	%r<65>;
	.reg .s16 	%rc<14>;


	ld.param.u32 	%r13, [update_kernel_param_0];
	ld.param.u32 	%r14, [update_kernel_param_1];
	// inline asm
	mov.u32 	%r3, %envreg3;
	// inline asm
	// inline asm
	mov.u32 	%r4, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r5, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r6, %tid.x;
	// inline asm
	add.s32 	%r15, %r6, %r3;
	mad.lo.s32 	%r16, %r5, %r4, %r15;
	// inline asm
	mov.u32 	%r7, %envreg4;
	// inline asm
	// inline asm
	mov.u32 	%r8, %ntid.y;
	// inline asm
	// inline asm
	mov.u32 	%r9, %ctaid.y;
	// inline asm
	// inline asm
	mov.u32 	%r10, %tid.y;
	// inline asm
	add.s32 	%r17, %r10, %r7;
	mad.lo.s32 	%r18, %r9, %r8, %r17;
	// inline asm
	mov.u32 	%r11, %envreg6;
	// inline asm
	// inline asm
	mov.u32 	%r12, %ntid.x;
	// inline asm
	mul.lo.s32 	%r19, %r12, %r11;
	mad.lo.s32 	%r20, %r12, %r11, %r18;
	mad.lo.s32 	%r21, %r12, %r11, %r16;
	add.s32 	%r22, %r21, -1;
	rem.u32 	%r23, %r22, %r19;
	add.s32 	%r24, %r20, -1;
	rem.u32 	%r25, %r24, %r19;
	mad.lo.s32 	%r26, %r25, %r19, %r23;
	add.s32 	%r27, %r13, %r26;
	ld.global.u8 	%rc1, [%r27];
	{
	.reg .s16 	%temp1;
	.reg .s16 	%temp2;
	cvt.s16.s8 	%temp1, %rc1;
	mov.b16 	%temp2, 0;
	cvt.s16.s8 	%temp2, %temp2;
	setp.ne.s16 	%p1, %temp1, %temp2;
	}
	selp.u32 	%r28, 1, 0, %p1;
	rem.u32 	%r29, %r20, %r19;
	mad.lo.s32 	%r30, %r29, %r19, %r23;
	add.s32 	%r31, %r13, %r30;
	ld.global.u8 	%rc2, [%r31];
	{
	.reg .s16 	%temp1;
	.reg .s16 	%temp2;
	cvt.s16.s8 	%temp1, %rc2;
	mov.b16 	%temp2, 0;
	cvt.s16.s8 	%temp2, %temp2;
	setp.eq.s16 	%p2, %temp1, %temp2;
	}
	selp.b32 	%r32, 2, 1, %p1;
	selp.b32 	%r33, %r28, %r32, %p2;
	add.s32 	%r34, %r20, 1;
	rem.u32 	%r35, %r34, %r19;
	mad.lo.s32 	%r36, %r35, %r19, %r23;
	add.s32 	%r37, %r13, %r36;
	ld.global.u8 	%rc3, [%r37];
	{
	.reg .s16 	%temp1;
	.reg .s16 	%temp2;
	cvt.s16.s8 	%temp1, %rc3;
	mov.b16 	%temp2, 0;
	cvt.s16.s8 	%temp2, %temp2;
	setp.ne.s16 	%p3, %temp1, %temp2;
	}
	selp.u32 	%r38, 1, 0, %p3;
	add.s32 	%r39, %r33, %r38;
	rem.u32 	%r40, %r21, %r19;
	mad.lo.s32 	%r41, %r25, %r19, %r40;
	add.s32 	%r42, %r13, %r41;
	ld.global.u8 	%rc4, [%r42];
	{
	.reg .s16 	%temp1;
	.reg .s16 	%temp2;
	cvt.s16.s8 	%temp1, %rc4;
	mov.b16 	%temp2, 0;
	cvt.s16.s8 	%temp2, %temp2;
	setp.ne.s16 	%p4, %temp1, %temp2;
	}
	selp.u32 	%r43, 1, 0, %p4;
	add.s32 	%r44, %r39, %r43;
	mad.lo.s32 	%r45, %r35, %r19, %r40;
	add.s32 	%r46, %r13, %r45;
	ld.global.u8 	%rc5, [%r46];
	{
	.reg .s16 	%temp1;
	.reg .s16 	%temp2;
	cvt.s16.s8 	%temp1, %rc5;
	mov.b16 	%temp2, 0;
	cvt.s16.s8 	%temp2, %temp2;
	setp.ne.s16 	%p5, %temp1, %temp2;
	}
	selp.u32 	%r47, 1, 0, %p5;
	add.s32 	%r48, %r44, %r47;
	add.s32 	%r49, %r21, 1;
	rem.u32 	%r50, %r49, %r19;
	mad.lo.s32 	%r51, %r25, %r19, %r50;
	add.s32 	%r52, %r13, %r51;
	ld.global.u8 	%rc6, [%r52];
	{
	.reg .s16 	%temp1;
	.reg .s16 	%temp2;
	cvt.s16.s8 	%temp1, %rc6;
	mov.b16 	%temp2, 0;
	cvt.s16.s8 	%temp2, %temp2;
	setp.ne.s16 	%p6, %temp1, %temp2;
	}
	selp.u32 	%r53, 1, 0, %p6;
	add.s32 	%r54, %r48, %r53;
	mad.lo.s32 	%r55, %r29, %r19, %r50;
	add.s32 	%r56, %r13, %r55;
	ld.global.u8 	%rc7, [%r56];
	{
	.reg .s16 	%temp1;
	.reg .s16 	%temp2;
	cvt.s16.s8 	%temp1, %rc7;
	mov.b16 	%temp2, 0;
	cvt.s16.s8 	%temp2, %temp2;
	setp.ne.s16 	%p7, %temp1, %temp2;
	}
	selp.u32 	%r57, 1, 0, %p7;
	add.s32 	%r58, %r54, %r57;
	mad.lo.s32 	%r59, %r35, %r19, %r50;
	add.s32 	%r60, %r13, %r59;
	ld.global.u8 	%rc8, [%r60];
	{
	.reg .s16 	%temp1;
	.reg .s16 	%temp2;
	cvt.s16.s8 	%temp1, %rc8;
	mov.b16 	%temp2, 0;
	cvt.s16.s8 	%temp2, %temp2;
	setp.ne.s16 	%p8, %temp1, %temp2;
	}
	selp.u32 	%r61, 1, 0, %p8;
	add.s32 	%r1, %r58, %r61;
	mad.lo.s32 	%r62, %r19, %r18, %r16;
	add.s32 	%r63, %r13, %r62;
	ld.global.u8 	%rc9, [%r63];
	{
	.reg .s16 	%temp1;
	.reg .s16 	%temp2;
	cvt.s16.s8 	%temp1, %rc9;
	mov.b16 	%temp2, 0;
	cvt.s16.s8 	%temp2, %temp2;
	setp.eq.s16 	%p9, %temp1, %temp2;
	}
	add.s32 	%r2, %r14, %r62;
	@%p9 bra 	BB2_4;

	add.s32 	%r64, %r1, -2;
	setp.gt.u32 	%p10, %r64, 1;
	@%p10 bra 	BB2_3;

	mov.u16 	%rc10, 1;
	st.global.u8 	[%r2], %rc10;
	ret;

BB2_3:
	mov.u16 	%rc11, 0;
	st.global.u8 	[%r2], %rc11;
	ret;

BB2_4:
	setp.eq.s32 	%p11, %r1, 3;
	@%p11 bra 	BB2_6;

	mov.u16 	%rc12, 0;
	st.global.u8 	[%r2], %rc12;
	ret;

BB2_6:
	mov.u16 	%rc13, 1;
	st.global.u8 	[%r2], %rc13;
	ret;
}


